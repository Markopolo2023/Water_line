{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IWT Water Treatment Dashboard\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This project transforms legacy water testing reports (PDFs and DOCX files) into a modern, interactive dashboard for water quality analysis in industrial settings (e.g., cooling towers, boilers). It showcases skills in **data extraction**, **ETL pipelines**, **database management**, and **interactive visualization**, ideal for data engineering and analytics roles.\n",
        "\n",
        "**Key Components:**\n",
        "- **Data Pulling/Sorting**: Collect and categorize reports (`pull.py`, `sort.py`).\n",
        "- **Data Extraction**: Parse PDFs (`pdf_process.py`) and DOCX (`docx_process.py`).\n",
        "- **Data Storage**: Store in SQLite with optional MSSQL export (`mssql_exporter.py`).\n",
        "- **Dashboard**: Interactive Dash/Plotly interface (`app.py`, `rules.py`).\n",
        "\n",
        "Repository: [GitHub - Water_line](https://github.com/Markopolo2023/Water_line)\n",
        "\n",
        "**Technologies:**\n",
        "- Python: `pandas`, `dash`, `plotly`, `pdfplumber`, `python-docx`, `PyPDF2`, `sqlite3`, `pyodbc`\n",
        "- Data Processing: Custom parsers for inconsistent formats\n",
        "- Visualization: Dash with dropdowns, charts, and rule-based insights\n",
        "\n",
        "**Note**: Data files (`pr/`, `dr/`, `combined.db`) are excluded for privacy. Contact me for a demo with anonymized data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Pulling Reports\n",
        "\n",
        "`pull.py` recursively collects PDF/DOCX reports from 'Site Visit Reports' folders and copies them to a destination (e.g., `pr/` or `dr/`). It handles filename conflicts by appending counters.\n",
        "\n",
        "**Sample Code**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def extract_reports(root_dir, dest_dir):\n",
        "    if not os.path.exists(dest_dir):\n",
        "        os.makedirs(dest_dir)\n",
        "    copied_files = 0\n",
        "    target_name = 'site visit reports'.lower()\n",
        "    for dirpath, _, filenames in os.walk(root_dir):\n",
        "        if os.path.basename(dirpath).lower() == target_name:\n",
        "            for subpath, _, subfiles in os.walk(dirpath):\n",
        "                for filename in subfiles:\n",
        "                    if filename.lower().endswith(('.pdf', '.docx')):\n",
        "                        source_path = os.path.join(subpath, filename)\n",
        "                        dest_path = os.path.join(dest_dir, filename)\n",
        "                        if os.path.exists(dest_path):\n",
        "                            base, ext = os.path.splitext(filename)\n",
        "                            counter = 1\n",
        "                            while os.path.exists(os.path.join(dest_dir, f'{base}_{counter}{ext}')):\n",
        "                                counter += 1\n",
        "                            dest_path = os.path.join(dest_dir, f'{base}_{counter}{ext}')\n",
        "                        shutil.copy(source_path, dest_path)\n",
        "                        copied_files += 1\n",
        "    print(f'Copied {copied_files} files to {dest_dir}.')\n",
        "\n",
        "# Example: extract_reports('C:\\\\', 'C:\\\\Users\\\\MD Eschbach\\\\Desktop\\\\thingsispendmytimeone\\\\Coding\\\\Projects\\\\iwt_db\\\\Water_line\\\\pr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Sorting Reports\n",
        "\n",
        "`sort.py` classifies PDFs into `handwritten`, `excel_table`, or `docx_to_pdf` based on metadata and content, moving them to respective folders. DOCX files go to `docx/`.\n",
        "\n",
        "**Sample Code**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "def classify_pdf(pdf_path):\n",
        "    try:\n",
        "        reader = PdfReader(pdf_path)\n",
        "        text = ''.join(page.extract_text() or '' for page in reader.pages).strip()\n",
        "        metadata = reader.metadata\n",
        "        producer = str(metadata.get('/Producer', 'None')).lower() if metadata else ''\n",
        "        creator = str(metadata.get('/Creator', 'None')).lower() if metadata else ''\n",
        "        if len(text) == 0:\n",
        "            return 'handwritten'\n",
        "        if any(k in producer or k in creator for k in ['excel', 'xls']):\n",
        "            return 'excel_table'\n",
        "        if any(k in producer or k in creator for k in ['word', 'docx']):\n",
        "            return 'docx_to_pdf'\n",
        "        return 'excel_table' if 'Comments and Recommendations:' not in text else 'docx_to_pdf'\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Example: sort_files('C:\\\\Users\\\\MD Eschbach\\\\Desktop\\\\thingsispendmytimeone\\\\Coding\\\\Projects\\\\iwt_db\\\\Water_line\\\\pr', recursive=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Extracting Data from PDFs\n",
        "\n",
        "`pdf_process.py` extracts facility details, dates, chemists, and metrics from PDFs using `pdfplumber`, handling varied table formats and saving as JSON in `data_processing/`.\n",
        "\n",
        "**Sample Code**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pdfplumber\n",
        "import os\n",
        "import json\n",
        "\n",
        "def main():\n",
        "    input_dir = 'pr'\n",
        "    output_dir = 'data_processing'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    for file_name in os.listdir(input_dir):\n",
        "        if file_name.lower().endswith('.pdf'):\n",
        "            try:\n",
        "                pdf_path = os.path.join(input_dir, file_name)\n",
        "                data = extract_data_from_pdf(pdf_path)  # Assume defined from pdf_process.py\n",
        "                output_file = os.path.splitext(file_name)[0] + '.json'\n",
        "                output_path = os.path.join(output_dir, output_file)\n",
        "                with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(data, f, indent=4)\n",
        "                print(f'Processed {file_name}')\n",
        "            except Exception as e:\n",
        "                print(f'Error processing {file_name}: {e}')\n",
        "\n",
        "# main()  # Uncomment to run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Extracting Data from DOCX\n",
        "\n",
        "`docx_process.py` parses DOCX files for dates, facilities, signatures, and measurements, saving as JSON.\n",
        "\n",
        "**Sample Code**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from docx import Document\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "input_dir = Path('dr')\n",
        "output_dir = Path('data_processing')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "for file_path in input_dir.glob('*.docx'):\n",
        "    try:\n",
        "        extracted_data = extract_data(file_path)  # Assume defined from docx_process.py\n",
        "        output_file = output_dir / f'{file_path.stem}.json'\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(extracted_data, f, indent=2)\n",
        "        print(f'Processed {file_path.name}')\n",
        "    except Exception as e:\n",
        "        print(f'Error processing {file_path.name}: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Exporting to Database\n",
        "\n",
        "`mssql_exporter.py` standardizes and stores JSON data in SQLite (`combined.db`), with optional MSSQL export.\n",
        "\n",
        "**Sample Code**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "\n",
        "try:\n",
        "    conn = sqlite3.connect('mssql_export/combined.db')\n",
        "    df = pd.read_sql_query('SELECT * FROM data', conn)\n",
        "    print(df.head())\n",
        "    conn.close()\n",
        "except Exception as e:\n",
        "    print(f'Data loading failed: {e}. Sample data not included in public repo.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Rules for Analysis\n",
        "\n",
        "`rules.py` defines ideal ranges and impact/suggestion logic for water quality metrics (e.g., pH, conductivity).\n",
        "\n",
        "**Sample Rules**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "METRIC_RULES = {\n",
        "    'ph': {'ideal_min': 7.5, 'ideal_max': 9.0, 'impact_factor': 0.15, 'base_cost': 10000,\n",
        "           'high_impact': 'High pH promotes scaling, increasing energy costs.',\n",
        "           'low_impact': 'Low pH causes corrosion, leading to equipment damage.'}\n",
        "    # Add more metrics as needed\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Interactive Dashboard\n",
        "\n",
        "`app.py` builds a Dash app with dropdowns, line charts, and rule-based insights.\n",
        "\n",
        "**Sample Visualization** (run locally for interactivity):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data for static plot\n",
        "df = pd.DataFrame({\n",
        "    'date': pd.date_range('2025-01-01', periods=10),\n",
        "    'conductivity': [1200, 1300, 1250, 1400, 1350, 1280, 1450, 1500, 1320, 1270]\n",
        "})\n",
        "fig = px.line(df, x='date', y='conductivity', title='Sample Conductivity Trend',\n",
        "              labels={'conductivity': 'Conductivity (µS/cm)'}, template='plotly_dark')\n",
        "fig.update_traces(line_color='#E84A27', line_width=3)\n",
        "fig.show()\n",
        "\n",
        "# Run app.py for the full dashboard: python Water_line/app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dashboard Preview\n",
        "\n",
        "![Dashboard Screenshot](images/dashboard_screenshot.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This pipeline modernizes water report processing, enabling data-driven decisions via a robust ETL process and interactive dashboard.\n",
        "\n",
        "**Skills Demonstrated**:\n",
        "- Data extraction from unstructured PDFs/DOCX.\n",
        "- ETL pipeline with SQLite storage.\n",
        "- Interactive visualization with Dash/Plotly.\n",
        "\n",
        "**Next Steps for Employers**:\n",
        "- View on GitHub: [IWT_Dashboard.ipynb](https://github.com/Markopolo2023/Water_line/blob/main/jupyter_nb/IWT_Dashboard.ipynb)\n",
        "- Run locally or contact me for a live demo.\n",
        "- Reach out via [GitHub Issues](https://github.com/Markopolo2023/Water_line/issues)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}